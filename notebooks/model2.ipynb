{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "w5s1dC3K1L2e",
    "outputId": "eae62a3e-a12d-4552-8a48-6f659bf6a454"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'X_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_train.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_train.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m X_val   \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_val.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\_npyio_impl.py:451\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    449\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    452\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'X_train.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    brier_score_loss,\n",
    "    log_loss,\n",
    "    average_precision_score,  # PR-AUC\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# Preprocessing + Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load data\n",
    "X_train = np.load(\"X_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "X_val   = np.load(\"X_val.npy\")\n",
    "y_val   = np.load(\"y_val.npy\")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:  \", X_val.shape)\n",
    "print(\"Positive rate (train):\", y_train.mean())\n",
    "print(\"Positive rate (val):  \", y_val.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qyeyf-8j80ir",
    "outputId": "5019084c-0734-44dd-e84b-68bb009e59f5"
   },
   "outputs": [],
   "source": [
    "# Class counts for imbalance handling\n",
    "n_pos = (y_train == 1).sum()\n",
    "n_neg = (y_train == 0).sum()\n",
    "\n",
    "print(\"Train positives:\", n_pos)\n",
    "print(\"Train negatives:\", n_neg)\n",
    "\n",
    "# Similar to logistic pos_weight: negatives / positives\n",
    "pos_weight = n_neg / n_pos\n",
    "class_weight = {0: 1.0, 1: float(pos_weight)}\n",
    "\n",
    "print(\"Computed pos_weight (neg/pos):\", pos_weight)\n",
    "print(\"Using class_weight:\", class_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "nnPkNlHR85kL",
    "outputId": "3afaac51-69a0-4cc8-97b6-325ddd4e29fb"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Build a pipeline: StandardScaler -> MLPClassifier\n",
    "ann_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"mlp\", MLPClassifier(\n",
    "        hidden_layer_sizes=(64, 32),  # 2 hidden layers\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        learning_rate_init=1e-3,\n",
    "        max_iter=30,\n",
    "        alpha=1e-4,\n",
    "        class_weight=class_weight,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def fit_ann_model(pipe, X_train, y_train):\n",
    "    return pipe.fit(X_train, y_train)\n",
    "\n",
    "ann_model = fit_ann_model(ann_pipeline, X_train, y_train)\n",
    "print(\"ANN model trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "gaFIevqk85rB",
    "outputId": "b5e0dc61-8b3d-4696-b58c-bb5022d4b750"
   },
   "outputs": [],
   "source": [
    "def hit_rate_at_k(y_true, y_prob, k):\n",
    "    # Measures what fraction of the top-k highest-probability cells actually had a crash.\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "\n",
    "    idx_sorted = np.argsort(y_prob)[::-1]\n",
    "    top_idx = idx_sorted[:k]\n",
    "    hits = y_true[top_idx].sum()\n",
    "    return hits / float(k)\n",
    "\n",
    "\n",
    "# Get probabilities on validation set\n",
    "y_val_proba = ann_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "brier = brier_score_loss(y_val, y_val_proba)\n",
    "logloss = log_loss(y_val, y_val_proba)\n",
    "pr_auc = average_precision_score(y_val, y_val_proba)\n",
    "roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "\n",
    "# Choose a k for hit-rate\n",
    "k = 500\n",
    "hr_k = hit_rate_at_k(y_val, y_val_proba, k)\n",
    "\n",
    "print(\"=== ANN (MLP) Model â€“ Validation Metrics ===\")\n",
    "print(f\"Brier score:        {brier:.6f}\")\n",
    "print(f\"Log-loss:           {logloss:.6f}\")\n",
    "print(f\"PR-AUC (avg prec):  {pr_auc:.6f}\")\n",
    "print(f\"ROC-AUC:            {roc_auc:.6f}\")\n",
    "print(f\"Hit-rate@k (k={k}): {hr_k:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
